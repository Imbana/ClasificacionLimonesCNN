{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Codigo proyecto final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imbana/ClasificacionLimonesCNN/blob/editar/Codigo_proyecto_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YypcA2Olmc6p"
      },
      "source": [
        "---\n",
        "# Clasificacion de limones Tahiti con redes neuronales convolucionales (CCN)\n",
        "---\n",
        "se recomienda configurar el enterno de ejecucion con TPU(Una unidad de procesamiento tensorial) sirve como acelerador de IA desarrollado por Google para el aprendizaje automático con redes neuronales artificiales y más específicamente optimizado para usar TensorFlow. entorno de ejecucion>>cambiar tipo de entorno de ejecucion>>TPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d4cZA1Um6AH"
      },
      "source": [
        "CONFIGURACION DEL ENTORNO Y LIBRERIAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkje8ZvOmSTL",
        "outputId": "59a92cd3-01a5-4c97-8347-bef34e30dac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#se conecta con google drive donde se encuentran las carpetas con las imagenes de los limones\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K6x_cOrnVtG"
      },
      "source": [
        "#librerias\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "import PIL\n",
        "import glob\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "#from tensorflow.keras import models\n",
        "\n",
        "from tensorflow import lite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV4ap3ntnmkz"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St8sQILitICN"
      },
      "source": [
        "---\n",
        "#Generar el dataset\n",
        "---\n",
        "Se copia la ruta de la carpeta donde estan las imagenes y se realiza una generacion de dataset con las caracteristicas necesarias como tamaño de imagen, escala, rotacion, tamaño de batch etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEbacb_KBQpw"
      },
      "source": [
        "PREPOCESAMIENTO DE LAS IMAGENES\n",
        "\n",
        "Para este paso se necesita carpetas de imagenes con las categorias de limones, o lo que se quiera clasificar, en nuestro caso 3 carpetas diferentes con imagenes de limones con Acaros, Buenos y con manchas\n",
        "\n",
        "\n",
        "Antes de crear los arrays que entran a la red neuronal se necesita hacerle un preprocesamiento a estas carpetas o datos, se necesita dividir en tres tipo de datos, los de entrenamiento y los de validacion (test y para prueba), se necesita que las imagenes sean aleatorias, y que cada carpeta poseea la misma cantidad de imagenes para no sobresaturar un clase, ademas de que podemos aumetar el dataset con modificaciones a las imagenes modificaciones como de rotacion, modificacion de entorno, color etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JU42Xqev6uU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrbsW0MqQqvU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQRmjDFuBLrH"
      },
      "source": [
        "# crear las carpetas, se necesita la carpeta Train, Test y prueba. dentro de esta 3 carpetas  para las clases de limones\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# la primera ruta es la direccion donde se va a guardar los datos\n",
        "#new_folder_path = os.path.join('/content/drive/My Drive/Proyecto_grado/Fotos/Datos4Clases')\n",
        "\n",
        "new_folder_path = os.path.join('/DatosPrueba')\n",
        "\n",
        "Data_train=os.path.join(new_folder_path,'Datos_Train')\n",
        "Data_test=os.path.join(new_folder_path,'Datos_Test')\n",
        "Data_prueba=os.path.join(new_folder_path,'Datos_Prueba')\n",
        "\n",
        "if not os.path.exists(new_folder_path): # Check la existencia del directorio\n",
        "    os.mkdir(new_folder_path)\n",
        "    os.mkdir(Data_train)\n",
        "    os.mkdir(Data_test)\n",
        "    os.mkdir(Data_prueba)\n",
        "    #os.mkdir(os.path.join(Data_train,\"Maduros\"))\n",
        "    os.mkdir(os.path.join(Data_train,\"Acaros\"))\n",
        "    os.mkdir(os.path.join(Data_train,\"Buenos\"))\n",
        "    os.mkdir(os.path.join(Data_train,\"Manchas\"))\n",
        "    #os.mkdir(os.path.join(Data_test,\"Maduros\"))\n",
        "    os.mkdir(os.path.join(Data_test,\"Acaros\"))\n",
        "    os.mkdir(os.path.join(Data_test,\"Buenos\"))\n",
        "    os.mkdir(os.path.join(Data_test,\"Manchas\"))\n",
        "    #os.mkdir(os.path.join(Data_prueba,\"Maduros\"))\n",
        "    os.mkdir(os.path.join(Data_prueba,\"Acaros\"))\n",
        "    os.mkdir(os.path.join(Data_prueba,\"Buenos\"))\n",
        "    os.mkdir(os.path.join(Data_prueba,\"Manchas\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Copia de datos de /Fotos/Maduros a /Fotos/Data/Maduros version 2.0\n",
        "\n",
        "#ruta donde se encuentran los datos originales\n",
        "parent_dir = '/content/drive/My Drive/Proyecto_grado/Fotos/Raw-Data'\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Lista los datos de la carpeta y los pone aleatoriamente  (desordena las imagenes)\n",
        "f_b = glob.glob(os.path.join(parent_dir,'Buenos','*.jpg'))\n",
        "random.shuffle(f_b)\n",
        "\n",
        "#f_m = glob.glob(os.path.join(parent_dir,'Maduros','*.jpg')) \n",
        "#random.shuffle(f_m)\n",
        "\n",
        "f_a = glob.glob(os.path.join(parent_dir,'Acaros','*.jpg'))  \n",
        "random.shuffle(f_a)\n",
        "\n",
        "f_s = glob.glob(os.path.join(parent_dir,'Manchas','*.jpg'))  \n",
        "random.shuffle(f_s)\n",
        "\n",
        "\n",
        "##################################################\n",
        "# ver la carpeta con menos datos 4 clases\n",
        "\n",
        "#valores=[len(f_b),len(f_m),len(f_a),len(f_s)]\n",
        "\n",
        "\n",
        "valores=[len(f_b),len(f_a),len(f_s)] # para tres clases\n",
        "\n",
        "print(min(valores))\n",
        "\n",
        "\n",
        "print('Buenos: {}'.format(len(f_b)))\n",
        "#print('Maduros: {}'.format(len(f_m)))\n",
        "print('Acaros: {}'.format(len(f_a)))\n",
        "print('Manchas: {}'.format(len(f_s)))\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# pegar las imagenes en las nuevas carpetas\n",
        "\n",
        "limit = min(valores)\n",
        "\n",
        "limite70=int(limit*0.8)\n",
        "limite20=int(limit*0.15)\n",
        "limite10=int(limit*0.05)\n",
        "\n",
        "i = 0\n",
        "for f in range(limite70):\n",
        "  # nombre de la imagen\n",
        "  name = 'train' + str(i) + '.jpg'\n",
        "  \n",
        "  n1 = 'h' + str(i) + '.jpg' # New name for the images flip horizontal\n",
        "  n2 = 'v' + str(i) + '.jpg' # New name for the images flip vertical\n",
        "#  n3 = 'r' + str(i) + '.jpg' # New name for the images rotated\n",
        "\n",
        "\n",
        "#pegar una imagen en un nuevo path con un nuevo nombre (Train)\n",
        "\n",
        "  #im = Image.open(f_s[f])\n",
        "  #i1=im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "  #i1.save(os.path.join(os.path.join(Data_train, 'Manchas'), n1), quality=95)\n",
        "  #i2 = im.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
        "  #i2.save(os.path.join(os.path.join(Data_train, 'Manchas'), n2), quality=95)\n",
        "  shutil.copy(f_s[f], os.path.join(os.path.join(Data_train, 'Manchas'), name))\n",
        "\n",
        "  #im = Image.open(f_b[f])\n",
        "  #i1=im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "  #i1.save(os.path.join(os.path.join(Data_train, 'Buenos'), n1), quality=95)\n",
        "  #i2 = im.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
        "  #i2.save(os.path.join(os.path.join(Data_train, 'Buenos'), n2), quality=95)\n",
        "  shutil.copy(f_b[f], os.path.join(os.path.join(Data_train, 'Buenos'), name))\n",
        "\n",
        "  #shutil.copy(f_m[f], os.path.join(os.path.join(Data_train, 'Maduros'), name))\n",
        "  #im = Image.open(f_a[f])\n",
        "  #i1=im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "  #i1.save(os.path.join(os.path.join(Data_train, 'Acaros'), n1), quality=95)\n",
        "  #i2 = im.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
        "  #i2.save(os.path.join(os.path.join(Data_train, 'Acaros'), n2), quality=95)\n",
        "  shutil.copy(f_a[f], os.path.join(os.path.join(Data_train, 'Acaros'), name))\n",
        "  \n",
        "  i+=1\n",
        "\n",
        "#pegar una imagen en un nuevo path con un nuevo nombre (Test)\n",
        "i = 0\n",
        "for f in range(limite70,limite70+limite20):\n",
        "\n",
        "  name = 'test' + str(i) + '.jpg'\n",
        "\n",
        "  n1 = 'h' + str(i) + '.jpg' # New name for the images flip horizontal\n",
        "  n2 = 'v' + str(i) + '.jpg' # New name for the images flip vertical\n",
        "#  n3 = 'r' + str(i) + '.jpg' # New name for the images rotated\n",
        "\n",
        "\n",
        "#pegar una imagen en un nuevo path con un nuevo nombre (Train)\n",
        "\n",
        "  #im = Image.open(f_s[f])\n",
        "  #i1=im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "  #i1.save(os.path.join(os.path.join(Data_test, 'Manchas'), n1), quality=95)\n",
        "  #i2 = im.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
        "  #i2.save(os.path.join(os.path.join(Data_test, 'Manchas'), n2), quality=95)\n",
        "  shutil.copy(f_s[f], os.path.join(os.path.join(Data_test, 'Manchas'), name))\n",
        "\n",
        "  #im = Image.open(f_b[f])\n",
        "  #i1=im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "  #i1.save(os.path.join(os.path.join(Data_test, 'Buenos'), n1), quality=95)\n",
        "  #i2 = im.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
        "  #i2.save(os.path.join(os.path.join(Data_test, 'Buenos'), n2), quality=95)\n",
        "  shutil.copy(f_b[f], os.path.join(os.path.join(Data_test, 'Buenos'), name))\n",
        "\n",
        "  #shutil.copy(f_m[f], os.path.join(os.path.join(Data_train, 'Maduros'), name))\n",
        "  #im = Image.open(f_a[f])\n",
        "  #i1=im.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "  #i1.save(os.path.join(os.path.join(Data_test, 'Acaros'), n1), quality=95)\n",
        "  #i2 = im.transpose(PIL.Image.FLIP_TOP_BOTTOM)\n",
        "  #i2.save(os.path.join(os.path.join(Data_test, 'Acaros'), n2), quality=95)\n",
        "  shutil.copy(f_a[f], os.path.join(os.path.join(Data_test, 'Acaros'), name))\n",
        "  \n",
        "  i+=1\n",
        "\n",
        "\n",
        "#pegar una imagen en un nuevo path con un nuevo nombre (Prueba)\n",
        "i = 0\n",
        "for f in range(limite70+limite20,limite70+limite20+limite10):\n",
        "\n",
        "  name = 'prueba' + str(i) + '.jpg'\n",
        "  #n3 = 'r' + str(i) + '.jpg' # New name for the images rotated\n",
        "\n",
        "  shutil.copy(f_s[f], os.path.join(os.path.join(Data_prueba, 'Manchas'), name))\n",
        "  shutil.copy(f_b[f], os.path.join(os.path.join(Data_prueba, 'Buenos'), name))\n",
        "  #shutil.copy(f_m[f], os.path.join(os.path.join(Data_prueba, 'Maduros'), name))\n",
        "  shutil.copy(f_a[f], os.path.join(os.path.join(Data_prueba, 'Acaros'), name))\n",
        "  \n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVMZmGHfZP3Q",
        "outputId": "2ca5d165-b8f1-4b27-f22b-f83493ed51d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# mirar cuantas imagenes tiene cada carpeta\n",
        "\n",
        "parent_dir = '/content/drive/My Drive/Proyecto_grado/Fotos/Raw-Data'\n",
        "\n",
        "\n",
        "f_b = glob.glob(os.path.join(parent_dir,'Buenos','*.jpg'))\n",
        "\n",
        "#f_m = glob.glob(os.path.join(parent_dir,'Maduros','*.jpg')) \n",
        "\n",
        "f_a = glob.glob(os.path.join(parent_dir,'Acaros','*.jpg'))  \n",
        "\n",
        "f_s = glob.glob(os.path.join(parent_dir,'Manchas','*.jpg'))  \n",
        "\n",
        "\n",
        "print('Buenos: {}'.format(len(f_b)))\n",
        "#print('Maduros: {}'.format(len(f_m)))\n",
        "print('Acaros: {}'.format(len(f_a)))\n",
        "print('Manchas: {}'.format(len(f_s)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buenos: 1295\n",
            "Acaros: 642\n",
            "Manchas: 758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4RvKMVfcrpT"
      },
      "source": [
        "#enpaquetar zip o inlcuso otros formatos\n",
        "\n",
        "import shutil\n",
        "\n",
        "archivo_zip = shutil.make_archive(\"/content/drive/My Drive/Dataset/Dataset3Clases\", \"zip\", \"/DatosPrueba\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEv-rETXpOAA"
      },
      "source": [
        "%ls\n",
        "%cd /.. #llevar el directorio a la carpeta\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sCAQ-k9qIxa"
      },
      "source": [
        "# Archivo a copiar    #Path donde se va a copiar solo copiar\n",
        "\n",
        "%cp -av /DatosPrueba /content/drive/My\\ Drive/Dataset/Datos3Clases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUhC2mCxplQ9"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "TRAINING_DIR = \"/DatosPrueba/Datos_Train\" #Data_train\n",
        "\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "\n",
        "VALIDATION_DIR = \"/DatosPrueba/Datos_Test\" #Data_test\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(224,224),\n",
        "\tclass_mode='categorical',\n",
        "  shuffle=True,\n",
        "  batch_size=32\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(224,224),\n",
        "\tclass_mode='categorical',\n",
        "  shuffle=True,\n",
        "  batch_size=32\n",
        ")\n",
        "\n",
        "\n",
        "#visualizar informacion del dataset\n",
        "\n",
        "image_batch_train, label_batch_train = next(iter(train_generator))\n",
        "\n",
        "print(\"composicion de un batch: \", image_batch_train.shape)\n",
        "print(\"composicion de la etiqueta: \", label_batch_train.shape)\n",
        "print(train_generator.class_indices)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjjgDp_Ww5-b"
      },
      "source": [
        "np.save('xtrain.npy',validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ITlwXO_-VlC"
      },
      "source": [
        "print(train_generator)\n",
        "print(validation_generator.n)\n",
        "print(train_generator.batch_size)\n",
        "print(train_generator.samples)\n",
        "print(validation_generator.batch_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsL3aYv4s1Ta"
      },
      "source": [
        "---\n",
        "#Configuracion del modelo de red neuronal\n",
        "---\n",
        "se extrae de la libreria de keras, luego de modifica sus capas finales para clasificar 3 tipos de clases \n",
        "\n",
        "```\n",
        "# Tiene\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_NEb1vX7MNi"
      },
      "source": [
        "#un modelo creado desde cero\n",
        "\"\"\"model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # Flatten the results to feed into a DNN\n",
        "    # \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHhQS5JhqB35"
      },
      "source": [
        "# se extrae un modelo base con sus pesos entrenados(weights='imagenet') y sin incluir las ultimas capas(include_top=False) luego se modifica agregando las ultimas capas\n",
        "def modelo1():\n",
        "\n",
        "  base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),\n",
        "                                                include_top=False, \n",
        "                                                weights='imagenet')\n",
        "  base_model.trainable = False\n",
        "  model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGZJUhERrzgs"
      },
      "source": [
        "#Creacion de otro modelo con menos capas finales ## mobile = keras.applications.mobilenet.MobileNet()\n",
        "\n",
        "\n",
        "def modelo2():\n",
        "    modeloV2 = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),include_top=False, weights='imagenet')\n",
        "    modeloV2.trainable = False\n",
        "    model = tf.keras.Sequential([modeloV2,\n",
        "                          keras.layers.GlobalAveragePooling2D(),\n",
        "                          keras.layers.Dense(3, activation='softmax')])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GAOSI4TzPN_"
      },
      "source": [
        "#mobile=modelo1()\n",
        "#mobile.summary()\n",
        "base_model = tf.keras.applications.MobileNet(input_shape=(224,224,3),\n",
        "                                                include_top=False, \n",
        "                                                weights='imagenet')\n",
        "\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y_f1c979vJJ"
      },
      "source": [
        "---\n",
        "##Entrenamiento del modelo\n",
        "---\n",
        "se especifica la configuracion del entrenamiento como tipo de optimizador de gradiente, funciin de costo, cuantas epocas  etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m2FustH8G2Z"
      },
      "source": [
        "#llama modelo\n",
        "model=modelo1()\n",
        "\n",
        "# configuro el entrenamiento de la red\n",
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# valores para pasos en epocas\n",
        "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "val_steps_per_epoch = np.ceil(validation_generator.samples/validation_generator.batch_size)\n",
        "\n",
        "# entrenamiento de la red neuronal\n",
        "history=model.fit(\n",
        "    \n",
        "    train_generator,\n",
        "    steps_per_epoch=18,\n",
        "    epochs=25,\n",
        "    verbose = 1,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=val_steps_per_epoch\n",
        "    \n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBK_ms-jhyys"
      },
      "source": [
        "---\n",
        "Pruebas del modelo o test del modelo entrenado\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTC5ytsi9uUK"
      },
      "source": [
        "# Evaluar en el modelo \n",
        "\n",
        "final_loss, final_accuracy = model.evaluate(validation_generator, steps =5)\n",
        "\n",
        "print(\"Final loss: {:.2f}\".format(final_loss))\n",
        "print(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))\n",
        "\n",
        "#mobileNETV2 primero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIM3JRPplpOD"
      },
      "source": [
        "#####\n",
        "\n",
        "#grafica del entrenamiento y la validacion\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "\n",
        "params = {\"text.color\" : \"red\",\n",
        "          \"xtick.color\" : \"white\",\n",
        "          \"ytick.color\" : \"white\"}\n",
        "plt.rcParams.update(params)\n",
        "plt.savefig(\"/content/Resultado.jpg\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73jtGM8Ti7GM"
      },
      "source": [
        "#prediccion de una imagen especifica\n",
        "\n",
        "# funion para preparar  una imagen para pasarla por el modelo entrenado\n",
        "Ruta=('/DatosPrueba/Datos_Prueba/Manchas/prueba15.jpg')\n",
        "img=plt.imread(Ruta)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img) # convertir en  array\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0) # agregar el cero\n",
        "    \n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)\n",
        "\n",
        "#prediccion\n",
        "preprocessed_image = prepare_image(Ruta)\n",
        "predictions = model.predict(preprocessed_image)\n",
        "print(predictions)\n",
        "print(train_generator.class_indices)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCOJpkJV-bG"
      },
      "source": [
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(dataset_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xJCfxEdVGI3"
      },
      "source": [
        "import pandas as pd\n",
        "val_image_batch, val_label_batch = next(iter(validation_generator))\n",
        "true_label_ids = np.argmax(val_label_batch, axis=-1)\n",
        "\n",
        "print(\"Validation batch shape:\", val_image_batch.shape)\n",
        "\n",
        "\n",
        "tf_model_predictions = model(val_image_batch)\n",
        "print(\"Prediction results shape:\", tf_model_predictions.shape)\n",
        "\n",
        "\n",
        "tf_pred_dataframe = pd.DataFrame(tf_model_predictions.numpy())\n",
        "tf_pred_dataframe.columns = dataset_labels\n",
        "\n",
        "print(\"Prediction results for the first elements\")\n",
        "tf_pred_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "834XXZ_cWRey"
      },
      "source": [
        "predicted_ids = np.argmax(tf_model_predictions, axis=-1)\n",
        "predicted_labels = dataset_labels[predicted_ids]\n",
        "\n",
        "\n",
        "#Print images batch and labels predictions\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(val_image_batch[n])\n",
        "  color = \"green\" if predicted_ids[n] == true_label_ids[n] else \"red\"\n",
        "  plt.title(predicted_labels[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")\n",
        "\n",
        "plt.savefig(\"/content/ImagenelimonesPrueba.jpg\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMN_KWlNi7g7"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# EXPORTAR TU MODELO A TFLITE\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "el modelo entrenado anteriormente esta en tensorflow ahora se buscar convertido a tensorflow lite para correrlo en la raspberry.\n",
        "\n",
        "se debe de crear tanto el modelo como las equites de salida para ver en que posicion esta cada categoria de limon(maduro, manchas, acaros, bueno)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcXph5gBjKm2"
      },
      "source": [
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"modelofinal.tflite\", 'wb').write(tflite_model)\n",
        "\n",
        "\n",
        "etiquetas=train_generator.class_indices\n",
        "file = open(\"/content/prueba.txt\", \"w\")\n",
        "for llaves in etiquetas.keys():\n",
        "  file.write(llaves + os.linesep)\n",
        "file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwGEAq7QqiU8"
      },
      "source": [
        "print(\"Number of layers in the base model: \", len(model.layers))\n",
        "\n",
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw-dCeQ1cH56"
      },
      "source": [
        "---\n",
        "# AXELERATE\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXRpsVZTcT3f",
        "outputId": "7df3e67c-f073-4b08-977d-d26e66949a9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        }
      },
      "source": [
        "\n",
        "#%tensorflow_version 1.x\n",
        "#we need imgaug 0.4 for image augmentations to work properly, see https://stackoverflow.com/questions/62580797/in-colab-doing-image-data-augmentation-with-imgaug-is-not-working-as-intended\n",
        "!pip uninstall -y imgaug && pip uninstall -y albumentations && pip install imgaug==0.4\n",
        "!git clone https://github.com/AIWintermuteAI/aXeleRate.git\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/aXeleRate')\n",
        "from axelerate import setup_training,setup_inference\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling imgaug-0.4.0:\n",
            "  Successfully uninstalled imgaug-0.4.0\n",
            "\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\n",
            "Collecting imgaug==0.4\n",
            "  Using cached https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (1.18.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (7.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (3.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (0.16.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug==0.4) (1.7.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.4) (2.8.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug==0.4) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug==0.4) (2.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug==0.4) (4.4.2)\n",
            "Installing collected packages: imgaug\n",
            "Successfully installed imgaug-0.4.0\n",
            "fatal: destination path 'aXeleRate' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a7051d2abcc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/aXeleRate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maxelerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msetup_inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/aXeleRate/axelerate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/aXeleRate/axelerate/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgpu_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPUOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_process_gpu_memory_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'GPUOptions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYRpOjcPcXTS"
      },
      "source": [
        "TRAINING_DIR=(\"/DatosPrueba1/Datos_Train\")\n",
        "VALIDATION_DIR=(\"/DatosPrueba1/Datos_Test\")\n",
        "config = {\n",
        "    \"model\" : {\n",
        "        \"type\":                 \"Classifier\",\n",
        "        \"architecture\":         \"MobileNet1_0\",\n",
        "        \"input_size\":           224,\n",
        "        \"fully-connected\":      [],\n",
        "        \"labels\":               [],\n",
        "        \"dropout\" : \t\t0.2\n",
        "    },\n",
        "     \"weights\" : {\n",
        "            \"full\":   \t\t\t\t\"\",\n",
        "            \"backend\":   \t\t    \"imagenet\",\n",
        "            \"save_bottleneck\":      False\n",
        "        \n",
        "    },\n",
        "    \"train\" : {\n",
        "        \"actual_epoch\":         25,\n",
        "        \"train_image_folder\":   TRAINING_DIR,\n",
        "        \"train_times\":          4,\n",
        "        \"valid_image_folder\":   VALIDATION_DIR,\n",
        "        \"valid_times\":          4,\n",
        "        \"valid_metric\":         \"val_accuracy\",\n",
        "        \"batch_size\":           32,\n",
        "        \"learning_rate\":        1e-3,\n",
        "        \"saved_folder\":   \t\tF\"/content/drive/My Drive/Proyecto_grado/Fotos\",\n",
        "        \"first_trainable_layer\": \"\",\n",
        "        \"augumentation\":\t\t\t\tTrue\n",
        "    },\n",
        "    \"converter\" : {\n",
        "        \"type\":   \t\t\t\t[\"k210\",\"tflite\"]\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJqJRlBdcmkY"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "model_path = setup_training(config_dict=config)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}